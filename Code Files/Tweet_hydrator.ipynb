{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Social Media Data Collection (Twitter) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data collected consist mainly of the data gathered from Christian Lopez, Malolan Vasu, and Caleb Gallemore (2020) (Understanding the perception of COVID-19 policies by mining a multilanguage Twitter dataset. arXiv:cs.SI/2003.10359,2020 https://arxiv.org/abs/2003.10359). <br /><br /> \n",
    "However, they faced some technical issues which did not permit the collection of data for specific dates. \n",
    "<br /><br /> Therefore, data from the IEEE DataPort (Rabindra Lamsal, 2020. Coronavirus (COVID-19) Tweets Dataset. Available at: http://dx.doi.org/10.21227/781w-ef42) and Chen E, Lerman K, Ferrara E ( Tracking Social Media Discourse About the COVID-19 Pandemic: Development of a Public Coronavirus Twitter Data Set JMIR Public Health Surveill 2020;6(2):e19273 DOI: 10.2196/19273 PMID: 32427106 ) were used to form the social media dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- According to Twitter's terms of use, only tweet Ids can be provided as a dataset.\n",
    "- To retrieve the tweet's text and date, tweet hydration needs to be implemented. \n",
    "- The tweets are retrieved and saved in a csv file so that they can be used for the analysis.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pip install required libaries for tweet hydration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install twarc\n",
    "# !pip install jsonlines\n",
    "# !pip install pandas\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up Directory and Twarc authentication keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current directory is : C:\\Users\\D.Petkidis\\Desktop\\TweetsRS\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from IPython.display import clear_output\n",
    "\n",
    "dirpath = os.getcwd()\n",
    "print(\"current directory is : \" + dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twarc import Twarc\n",
    "\n",
    "# These keys are received after applying for a twitter developer account\n",
    "consumer_key = \"\" \n",
    "consumer_secret = \"\" \n",
    "access_token = \"\" \n",
    "access_token_secret = \"\"\n",
    "\n",
    "t = Twarc(consumer_key, consumer_secret, access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing keywords to hydrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "coronavirus = True \n",
    "virus = True \n",
    "covid = True \n",
    "ncov19 = True \n",
    "ncov2019 = True \n",
    "keyword_dict = {\"coronavirus\": coronavirus, \"virus\": virus, \"covid\": covid, \"ncov19\": ncov19, \"ncov2019\": ncov2019}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing start and end date (a file list with all the files corresponding to the selected dates is created)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The start and end date of the desired hydration timeframe are selected.\n",
    "- The files that contain the tweet ids for the selected keywords and dates are then selected from the corresponding folder and appended to a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the start and end date\n",
    "start_date = '2020-03-31'\n",
    "end_date = '2020-03-31' \n",
    "\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "files = []\n",
    "covid_loc = dirpath\n",
    "\n",
    "# Looks at each folder\n",
    "for folder in os.listdir(covid_loc):\n",
    "    foldername = os.fsdecode(folder)\n",
    "    \n",
    "    # The folder name is a keyword. We continue for keywords selected above\n",
    "    if keyword_dict.get(foldername.split()[0].lower()) == True:\n",
    "        folderpath = os.path.join(covid_loc, foldername)\n",
    "        # Each file is of the format [keyword]_yyyy_mm_dd.txt\n",
    "        for file in os.listdir(folderpath):\n",
    "            filename = os.fsdecode(file)\n",
    "            date = filename[filename.index(\"_\")+1:filename.index(\".\")]\n",
    "\n",
    "            # If the date is within the required range, it is added to the list of files to read.\n",
    "            if (dt.datetime.strptime(start_date, \"%Y-%m-%d\").date() \n",
    "            <= dt.datetime.strptime(date, '%Y_%m_%d').date()\n",
    "             <= dt.datetime.strptime(end_date, \"%Y-%m-%d\").date()):\n",
    "                \n",
    "                # print(dt.datetime.strptime(date, '%Y_%m_%d').date())\n",
    "                # print(filename.split('_', 1)[0])\n",
    "                files.append(os.path.join(folderpath, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A sample of the ids for each day are added to a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A set of the different dates that were selected is created.\n",
    "- Each file is opened and the tweet ids that are included in it are placed in a dataframe\n",
    "- The dataframe is then randomly sampled in order to reduce the volume of tweets\n",
    "(millions of tweets are collected for each day, however the computational resources cannot support the retrieval of all those tweets and therefore a part of them is selected)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020_03_31 1100934\n",
      "2020_03_31\n"
     ]
    }
   ],
   "source": [
    "# Gathering the set of the different dates that were selected\n",
    "dates = set()\n",
    "\n",
    "for filename in files:\n",
    "    dates.add(filename.split('_', 1)[1].split('.',1)[0])\n",
    "# print(dates)\n",
    "\n",
    "# The final list is read, and each of the individual IDs is stored in a collective\n",
    "# set of IDs for each date. Duplicates are removed.\n",
    "for date in dates:\n",
    "    ids = set()\n",
    "    for filename in files:\n",
    "        if date in filename:\n",
    "            # print(filename.split('_', 1)[1].split('.',1)[0]) --> prints file date\n",
    "            with open(filename) as f:\n",
    "                # The files are of the format: [id1,id2,id3,...,idn]\n",
    "                # Remove the brackets and split on commas\n",
    "                for i in f.readline().strip('][').replace(\" \", \"\").split(\",\"):\n",
    "                    ids.add(i) \n",
    "                # print(filename, len(ids))\n",
    "    # Append the ids in a pandas dataframe            \n",
    "    file_ids = list(ids)\n",
    "    df = pd.DataFrame(file_ids)\n",
    "    print(date, len(df))\n",
    "    # print(filename.split('_', 1)[0].split('\\\\')[-1]) --> prints file keyword\n",
    "\n",
    "    # Randomly sample 30000 tweets to hydrate for each day\n",
    "    if len(df) >= 30000:\n",
    "        sampledf = df.sample(n=30000, random_state=1)\n",
    "    else:\n",
    "        sampledf = df\n",
    "    print(date)\n",
    "    # Append the sampled ids for each day in the txt file that contains all the selected tweets from the desired timeframe\n",
    "    sampledf.to_csv(r'final_ids_{}.txt'.format(date), header=None, mode='a+', index=False)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweet Hydration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A dataframe containing the hydrated tweets for each date and all the chosen keywords is created.\n",
    "- The hydrated tweets are then converted to the necessary format. \n",
    "- The original text from Retweets is retrieved and placed in the dataframe. Duplicates are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1000 hydrated tweets.\n",
      "Saved 2000 hydrated tweets.\n",
      "Saved 3000 hydrated tweets.\n",
      "Saved 4000 hydrated tweets.\n",
      "Saved 5000 hydrated tweets.\n",
      "Saved 5000 hydrated tweets.\n",
      "Saved 5000 hydrated tweets.\n",
      "Saved 5000 hydrated tweets.\n",
      "Saved 6000 hydrated tweets.\n",
      "Saved 7000 hydrated tweets.\n",
      "Saved 7000 hydrated tweets.\n",
      "Saved 7000 hydrated tweets.\n",
      "Saved 8000 hydrated tweets.\n",
      "Saved 9000 hydrated tweets.\n",
      "Saved 10000 hydrated tweets.\n",
      "Saved 11000 hydrated tweets.\n",
      "Saved 12000 hydrated tweets.\n",
      "Saved 12000 hydrated tweets.\n",
      "Saved 13000 hydrated tweets.\n",
      "Saved 13000 hydrated tweets.\n",
      "Saved 14000 hydrated tweets.\n",
      "Saved 14000 hydrated tweets.\n",
      "Saved 15000 hydrated tweets.\n",
      "Saved 15000 hydrated tweets.\n",
      "Saved 15000 hydrated tweets.\n"
     ]
    }
   ],
   "source": [
    "cols = [\"created_at\", \"id_str\", \"full_text\", \"RT_text\", \"retweeted_status\", \"retweet_count\", \"place\"] \n",
    "count = 0\n",
    "num_save  = 1000\n",
    "length = 0\n",
    "\n",
    "for date in dates:\n",
    "    # creates an empty dataframe for each date\n",
    "    date_tweets = pd.DataFrame(columns = cols)\n",
    "    # Hydrates the tweets that were sampled for each date\n",
    "    for tweet in t.hydrate(open('final_ids_{}.txt'.format(date))):\n",
    "        # if (tweet['place'] is not None) and (tweet['place']['country'] == 'United Kingdom'):\n",
    "        if (tweet['lang'] == \"en\"):\n",
    "            date_tweets.at[count, \"created_at\"] = tweet[\"created_at\"]\n",
    "            date_tweets.at[count, \"id_str\"] = tweet[\"id_str\"]\n",
    "            date_tweets.at[count, 'full_text'] = tweet[\"full_text\"]\n",
    "            date_tweets.at[count, \"retweet_count\"] = tweet[\"retweet_count\"]\n",
    "            if \"retweeted_status\" in tweet:\n",
    "                date_tweets.at[count, \"RT_text\"] = tweet[\"retweeted_status\"]['full_text']\n",
    "            else:\n",
    "                date_tweets.at[count, \"RT_text\"] = tweet[\"full_text\"]\n",
    "                \n",
    "            count = count + 1  \n",
    "        # An indicator showing how many tweets were hydrated in thousands    \n",
    "        if (count % num_save) == 0:\n",
    "            print(\"Saved \" + str(count) + \" hydrated tweets.\")\n",
    "    # Converts created_at to datetime\n",
    "    date_tweets[\"created_at\"] = date_tweets[\"created_at\"].astype('datetime64[ns]') \n",
    "    date_tweets[\"created_at\"] = date_tweets.created_at.dt.to_pydatetime()\n",
    "    # Drops the duplicates\n",
    "    date_tweets_final = date_tweets.sort_values(\"RT_text\") \n",
    "    date_tweets_final = date_tweets_final.drop_duplicates(subset='RT_text', ignore_index=True)\n",
    "    date_tweets_final = date_tweets_final.drop(columns=['full_text', 'retweeted_status'], axis=1)\n",
    "    # Calculate total number of hydrated tweets\n",
    "    length = length + len(date_tweets_final)\n",
    "    \n",
    "    # Append hydrated tweets for each date to a file containing all the hydrated tweets for that period\n",
    "    # (Change file name based on chosen dates)\n",
    "    date_tweets_final.to_csv('ids_Mar31.csv', index=False, mode='a+')   # header=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The file that contains the tweets for the chosen date is loaded and the date is properly formatted. \n",
    "- The total number of hydrated tweets for the selected time period is printed\n",
    "- The total daily number of hydrated tweets is printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets: 12016\n"
     ]
    }
   ],
   "source": [
    "# Reads the file created from the hydration of the tweets\n",
    "test_ids = pd.read_csv(r'ids_Mar31.csv', sep=\",\", parse_dates=False)\n",
    "\n",
    "# The tweets were written in the file but the header was preserved so the rows that contain the name of the columns should\n",
    "# be removed.\n",
    "# print(test_ids[test_ids['created_at'].str.len() != 19])\n",
    "test_ids = test_ids[test_ids.created_at != 'created_at'].reset_index().drop(columns=['index'])\n",
    "test_ids[\"created_at\"] = test_ids[\"created_at\"].astype('datetime64[ns]') \n",
    "test_ids[\"created_at\"] = test_ids.created_at.dt.to_pydatetime()\n",
    "test_ids['created_at'] = test_ids['created_at'].dt.date\n",
    "\n",
    "print('Total tweets:', len(test_ids))\n",
    "# Writes the tweets in a file\n",
    "test_ids.to_csv(r'ids_final_Mar31.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020-03-31    12016\n",
       "Name: created_at, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prints the number of tweets for each date\n",
    "test_ids.created_at.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
